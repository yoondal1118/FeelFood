import os
import random
import numpy as np
import pandas as pd
import tensorflow as tf
from soynlp.normalizer import repeat_normalize
from transformers import AutoTokenizer, TFDistilBertModel

# ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ê²°ê³¼ê°€ ë˜‘ê°™ì´ ë‚˜ì˜¤ë„ë¡ í•´ì‰¬ê°’ì„ ê³ ì •í•©ë‹ˆë‹¤.
def reset_seeds(seed=42):
    os.environ['PYTHONHASHSEED'] = str(seed)
    tf.random.set_seed(seed)
    np.random.seed(seed)
    random.seed(seed)

reset_seeds() # í•¨ìˆ˜ ì‹¤í–‰

MAX_LEN = 128
MODEL_NAME = "monologg/distilkobert"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)

PATH = "./1200real/"
# ê°ì •ë³„ ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
EMOTION_FILES = {
    'í¬(Happy)':   f'{PATH}happy_model.h5',
    'ë…¸(Angry)':   f'{PATH}angry_model.h5',
    'ì• (Sad)':     f'{PATH}sad_model.h5',
    'ì• (Love)':    f'{PATH}love_model.h5',
    'ë½(Fun)':     f'{PATH}fun_model.h5',
    'ë¶ˆë§Œ(Complaint)': f'{PATH}complaint_model.h5'
}

class DistilBertLayer(tf.keras.layers.Layer):
    def __init__(self, model_name, **kwargs):
        super().__init__(**kwargs)
        self.bert = TFDistilBertModel.from_pretrained(model_name, from_pt=True)

    def call(self, inputs):
        input_ids = inputs[0]
        attention_mask = inputs[1]
        outputs = self.bert(input_ids, attention_mask=attention_mask)
        return outputs[0]

def clean_text(text):
    if not isinstance(text, str): return ""
    return repeat_normalize(text, num_repeats=2)

def build_model():
    input_ids = tf.keras.layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name="input_ids")
    attention_mask = tf.keras.layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name="attention_mask")

    bert_layer = DistilBertLayer(MODEL_NAME)
    last_hidden_state = bert_layer([input_ids, attention_mask])
    cls_token = last_hidden_state[:, 0, :]

    x = tf.keras.layers.Dropout(0.2)(cls_token)

    # ì´ë¦„ì„ ê°•ì œë¡œ ì§€ì •í•´ì¤ë‹ˆë‹¤ (ì €ì¥ëœ íŒŒì¼ê³¼ ë§ì¶”ê¸° ìœ„í•¨)
    output = tf.keras.layers.Dense(1, activation='sigmoid', name='dense')(x)

    model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=output)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# 2. ëª¨ë“  ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
def load_all_emotion_models(emotion_files):
    loaded_models = {}
    print(f"[ì‹œìŠ¤í…œ] ì´ {len(emotion_files)}ê°œì˜ ê°ì • ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")

    for emotion_name, file_path in emotion_files.items():
        if not os.path.exists(file_path):
            print(f"  [ê²½ê³ ] íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            continue

        try:
            # ë©”ëª¨ë¦¬ ì²­ì†Œ! ì´ê±¸ í•´ì•¼ ì´ë¦„ì´ dense_1, dense_2ë¡œ ì•ˆ ë°”ë€ë‹ˆë‹¤.
            tf.keras.backend.clear_session()

            model = build_model()
            model.load_weights(file_path, by_name=True)
            loaded_models[emotion_name] = model
            print(f"  - ë¡œë“œ ì„±ê³µ: {emotion_name}")

        except Exception as e:
            print(f"  [ì¹˜ëª…ì  ì˜¤ë¥˜] {emotion_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

    if not loaded_models:
        print("\n[ë¹„ìƒ] ë¡œë“œëœ ëª¨ë¸ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤!")
        exit()

    return loaded_models

my_models = load_all_emotion_models(EMOTION_FILES)

# 3. í†µí•© ì˜ˆì¸¡ í•¨ìˆ˜
def predict_multi_emotion(text, models, tokenizer):
    cleaned_text = clean_text(text)
    encodings = tokenizer(cleaned_text, truncation=True, padding='max_length', max_length=MAX_LEN, return_token_type_ids=False, return_tensors='tf')
    inputs = {'input_ids': encodings['input_ids'], 'attention_mask': encodings['attention_mask']}

    # í¼ì„¼íŠ¸ ì¡°ì ˆ
    BIAS_SCORES = {
        'í¬(Happy)': 0.0,
        'ë…¸(Angry)': 0.0,
        'ì• (Sad)': 0.0,
        'ì• (Love)': 0.0,
        'ë½(Fun)': 0.0,
        'ë¶ˆë§Œ(Complaint)': 0.0
    }

    scores = {}
    # print(f"\n[ìƒì„¸ ì ìˆ˜í‘œ] ë¬¸ì¥: {text[:20]}...")
    for emotion_name, model in models.items():
        try:
            pred = model(inputs, training=False)
            raw_prob = float(pred[0][0])

            bias = BIAS_SCORES.get(emotion_name, 0.0)
            final_prob = max(0.0, min(1.0, raw_prob + bias))

            scores[emotion_name] = round(final_prob, 4)
            # bar = "â– " * int(final_prob * 10)
            # print(f"  - {emotion_name}: {final_prob:.4f} (ì›ì ìˆ˜: {raw_prob:.4f}) {bar}")

        except Exception as e:
            scores[emotion_name] = 0.0

    if not scores: return "ì—ëŸ¬", 0.0, {}
    best_emotion = max(scores, key=scores.get)
    best_score = scores[best_emotion]
    return best_emotion, best_score, scores

# [í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° CSV ì €ì¥]
print("\n[ë‹¤ì¤‘ ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸]")
test_sentences = [
    "ë„ˆë¬´ ì´ë»ìš” ğŸ˜ğŸ˜ ë§›ìˆê³  ê±´ê°•í•œ ìŒì‹ì´ì—ìš”ğŸ˜‹ ê·¼ë° ë¹„ì‹¸ê¸´ í•©ë‹ˆë‹¤â€¦..ã…œ",
    "ì§€ì¤‘í•´ì‹ ê±´ê°•ì‹ ë¨¹ìœ¼ëŸ¬ ì™”ì–´ìš” ã…ã… ê±´ê°•í•˜ê·œ ë§›ìˆëŠ” ìŒì‹ ë¨¹êµ¬ íŠ¼íŠ¼í•´ì§€ê² ìŠµë‹ˆë‹¹ ã…ã… ê±´ê°•í•œ ìƒëŸ¬ë“œ ë§›ì§‘ì´ì—ìš”ğŸ«¶ğŸ»ğŸ«¶ğŸ»ğŸ«¶ğŸ»",
    "ë°ì´íŠ¸í•˜ê¸° ì¢‹ì€ ê³³. ë§›ìˆì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒì— ë˜ ì˜¤ê³  ì‹¶ì–´ìš” :)",
    "ë‚¨í¸ì´ë‘ ë°ì´íŠ¸! ì¡°ì•„ì¡°ì•„ìš” ^^",
    "ì™€ì´í”„ì™€ ì²˜ìŒ ë°©ë¬¸í–ˆìŠµë‹ˆë‹¤ ì¢€ ìƒ‰ë‹¤ë¥¸ê±¸ ë¨¹ê³  ì‹¶ì–´ì„œ ê²€ìƒ‰ í›„ ì™”ëŠ”ë° ìŒì‹ë„ ë§›ìˆê³  ë¶„ìœ„ê¸°ë„ ì¢‹ê³  ë°ì´íŠ¸í•˜ê¸°ì—” ê´œì°®ë„¤ìš”",
    "í•´ì™¸ ë¹„ê±´ì‹ë‹¹ì€ ë§ì§€ ì•Šì€ë° ì¢‹ë„¤ìš”~ ì—¬ëŸ¬ ê°€ì§€ ì‹œì¼œì„œ ê°™ì´ ë¨¹ê¸°ë„ ì¢‹ê³  ë§›ìˆì–´ìš”!",
    "ê±´ê°•í•˜ê³  ë§›ìˆëŠ” ì‹ì‚¬ë¥¼ í•  ìˆ˜ ìˆì–´ìš”ğŸ‘",
    "ì´ê±° ì™¸ì—ë„ ë©”ë‰´ ì—„ì²­ ì‹œì¼œë¨¹ì—ˆëŠ”ë° ì• ì¸ì´ë‘ ì™„ì „ ë°°ë¶€ë¥´ê³  ë§›ìˆê²Œ ë¨¹ê³ ê°‘ë‹ˆë‹µâ¤ï¸",
    "ì›¨ì´íŒ… ì—†ì´ ë°”ë¡œ ë“¤ì–´ì™”ìŠµë‹ˆë‹¤! ê°€ê²Œ ë¶„ìœ„ê¸° ë„˜ ì¢‹ê³  ìˆ˜ê°• ë“£ëŠ” ê³³ ê·¼ì²˜ì— ë¹„ê±´ ìŒì‹ì„ ë¨¹ì„ ìˆ˜ ìˆëŠ” ê°€ê²Œê°€ ìˆì–´ì„œ í¸í•˜ë„¤ìš”. ì¢…ì¢…ì˜¬ê²Œìš”!",
    "ì§ì›ë¶„ë“¤ë„ ë„ˆë¬´ ì¹œì ˆí•˜ì‹œê³  ìŒì‹ì´ ì •ë§ ë§›ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì— ë˜ ë°©ë¬¸í•˜ê² ìŠµë‹ˆë‹¤!",
    "íŠ¹ì´í•œ ìŒë£Œë„ ìˆê³  ì „ì²´ì ìœ¼ë¡œ ì•Œì°¨ê³  ê±´ê°•í•œ ë§›ì´ì—ìš”! ë¹„ê±´ ë©”ë‰´ë„ ìˆì–´ìš”.",
    "ë¶„ìœ„ê¸° ê·¸ë¦¬ê³  ìµœê³ ì˜ë§› ë¬´ìŠ¨ì„¤ëª…ì´ ë” í•„ìš”í•œê°€.",
    "ë‘ë²ˆì§¸ ë°©ë¬¸~~~ ì•ˆì£¼ë„ ë§›ìˆê³  í™”ì¥ì‹¤ë„ ê¹¨ë—í•´ì„œ ê±±ì •ì—†ì–´ìš”",
    "ì˜ë¨¹ì—ˆìŠµë‹ˆë‹¤ ë‹´ì— ë˜ ì˜¬ê²Œìš”",
    "ë¶„ìœ„ê¸°ê°€ ì¢‹ê³  ìŒì‹ì´ ì§„ì§œ ë§›ìˆì–´ìš”! íŠ¹íˆ ê¼¬ì¹˜",
    "íšŒê°€ ë‘íˆ¼í•˜ê³  ì‹±ì‹±í•˜ë„¤ìš” ê·¸ë¦¬ê³  ì°¹ìŒ€ê°€ë¼ì•„ê²Œ ìµœê³ ì—ìš”!!! ì°¹ìŒ€íƒ•ìˆ˜ìœ¡ì²˜ëŸ¼ ì«€ë“í•´ìš” ê°•ì¶”í•©ë‹ˆë‹¤",
    "ê¼¬ì¹˜ ë§›ë„ë¦¬",
    "ì¹œêµ¬ ì¶”ì²œìœ¼ë¡œ ë°©ë¬¸í–ˆëŠ”ë° ë§¤ì¥ë„ ê¹”ë”í•˜ê³  ë¶„ìœ„ê¸°ë„ ì¢‹ì•„ìš” ì¶”ì²œ!",
    "ìŒì‹ë„ ë§›ìˆê³  ì§ì›ë¶„ë“¤ì´ ì¹œì ˆí•˜ì…”ì„œ ë˜ ì˜¤ê³ ì‹¶ì–´ìš” ã…ã… ê±´ëŒ€ ì´ìì¹´ì•¼ ì¤‘ì— ì œì¼ ì¢‹ì•„ìš”!!ğŸ¥ºğŸ¥ºğŸ€",
    "ì•ˆì£¼ê°€ ë§›ìˆê³  ì¹œì ˆí•˜ì…”ìš”~~",
    "ë„ˆë¬´ ì‹ ì„ í•œ ë§›ì´ê³  ë¨¹ê³ ë‚˜ë©´ ì†ì´ í¸í•´ì„œ ì¢‹ì•„ìš”!!ë‹¤ìŒì— ë˜ ì™€ì„œ ë¨¹ê³ ì‹¶ì€ë§›:)",
    "ë‚¨í¸ê³¼ íŠ¹ë³„í•œ ë°ì´íŠ¸ë¥¼ ì¦ê¸°ê³  ì‹¶ì–´ì„œ ì°¾ë‹¤ê°€ ë°œê²¬í•œ ì´ìì¹´ì•¼ì˜€ì–´ìš” :) í™”ì¥ì‹¤ ë§ˆì €ë„ ì„¸ì‹¬í•œ ë°°ë ¤ê°€ ê°€ë“í•˜ê³  ìŒì‹ì€ ë”í• ë‚˜ìœ„ ì—†ì´ ë§›ìˆê³  ë¶„ìœ„ê¸°ë„ ì¢‹ì•„ì„œ ê±´ëŒ€ ì˜¬ ë•Œì— ê¼­ ì™€ì•¼í•˜ëŠ” ë§›ì§‘ìœ¼ë¡œ ì €ì¥í•˜ë ¤êµ¬ìš” ğŸ™ŒğŸ»",
    "ë§›ìˆê³  ê°€ê²©ë„ í•©ë¦¬ì ì´ê³  ì‚¬ì¥ë‹˜,ì§ì›ë“¤ ëª¨ë‘ ì¹œì ˆí•˜ì…”ì„œ ê¸°ë¶„ì¢‹ì€ í•˜ë£¨ì…ë‹ˆë‹¤ğŸ’•ğŸ’• ì–¼ê·¸ë ˆì´ í•˜ì´ë³¼ ë„ˆë¬´ ë§›ìˆì–´ìš”..ğŸ¤¤ ê·¼ì²˜ì— ì‚¬ëŠ”ë° ìì£¼ ë°©ë¬¸í•  ê²ƒ ê°™ì€ ëŠë‚Œ!!",
    "ìŒì‹ì´ ë§›ìˆì—ˆì–´ìš”. ì˜ë¨¹ì—ˆìŠµë‹ˆë‹¤",
    "ê±´ëŒ€ ì˜¤ë©´ ìƒê°ë‚˜ëŠ” ë¶„ìœ„ê¸° ì¢‹ê³  ë§›ìˆì–´ìš”ğŸ‘",
    "ë„ˆë¬´ ë§›ìˆì–´ì„œ ë˜ ë°©ë¬¸í–ˆì–´ìš”! ìë¦¬ê°€ ë¶€ì¡±í–ˆëŠ”ë° ì‚¬ì¥ë‹˜ì´ í…Œì´ë¸” ì—°ê²°í•´ì„œ ìë¦¬ ë§Œë“¤ì–´ì£¼ì…”ì„œ ëŒ€ê¸°ë„ ì—†ì—ˆì–´ìš” ì• ì •í•˜ëŠ” ë§›ì§‘ğŸ˜",
    "4ë²ˆì§¸ ë°©ë¬¸í•´ìš” ã…‹ã…‹ ë„ˆë¬´ ë§›ìˆì–´ì„œ ë˜ ì™”ì–´ìš” ã…‹ã…‹ğŸ˜",
    "ë¶ˆë§›ë‚˜ê³  ë„˜ ë§›ìˆì—ˆì–´ìš”!!",
    "ëŒ€ê¸°ì‹œê°„ìˆì§€ë§Œ ë„˜ ë§›ìˆì—ˆì–´ìš”!!",
    "ê¸‰í•˜ê²Œ ì°¾ê³  ì˜ˆì•½í•´ì„œ ê°”ëŠ”ë° ìœ ë ˆì¹´ ...! ì•ìœ¼ë¡œ ë‹¨ê³¨ì˜ˆì •ì…ë‹ˆë‹¤ âœŒğŸ»âœŒğŸ» ì‚¬ì¥ë‹˜ì´ ì •ë§ì •ë§ì •ë§ ë„ˆë¬´ë„ˆë¬´ë„ˆë¬´ ì¹œì ˆí•˜ì‹œê³ , ìŒì‹ì´ í•˜ë‚˜ í•˜ë‚˜ ë‹¤ ë§›ìˆì—ˆì–´ìš” ë‹¨ìƒˆìš°ëŠ” ì‹ê°ì´ ê¾¸ë•í•˜ê³  ì‹±ì‹±í–ˆê³ , ê¼¬ì¹˜êµ¬ì´ëŠ” ë¶ˆí–¥ì— ì«€ë”•ì«€ë”• ê¼¬ì†Œí–ˆìŠµë‹ˆë‹¤~!! ë¬´í•œ ê°ë™ ë°›ê³  ê°‘ë‹ˆë‹¤ ì—¬ëŸ¬ë¶„ ê±´ëŒ€ ì´ìì¹´ì•¼ë¥¼ ê°„ë‹¤ë©´ í•˜ë£¨ë¥¼ ê°•ë ¥í•˜ê²Œ ì¶”ì²œë“œë¦½ë‹ˆë‹¤ğŸ™ŒğŸ»",
    "ì‚¬ì‹œë¯¸ë‘ ê³ ë¡œì¼€ ë¨¹ì—ˆëŠ”ë° ë„ˆë¬´ ë§›ìˆì–´ë‡¨$_<!!!!ì‚¬ì¥ë‹˜ ê·¸ë¦¬ê³  ë„ˆë¬´ ì¹œì ˆí•˜ì…”ì„œ ì¢‹ì•˜ìŠµë‹ˆë‹¤!!!",
    "ì‚¬ì‹œë¯¸ ë„ˆë¬´ ë§›ìˆì–´ìš”! ì´ìì¹´ì•¼ ì‚¬ì‹œë¯¸ì¤‘ ê°€ì„±ë¹„ ìë¦¬ë„ ë¶„ìœ„ê¸°ë„ ì•„ëŠ‘í•´ì„œ ì—¬ìì¹œêµ¬ë‘ ì–˜ê¸°í•˜ê¸°ì¢‹ì•˜ì—‰ã……!",
    "ë§›ìˆê³  ì¹œì ˆí•´ìš” ë‹¤ìŒì— ë˜ ì˜¤ê³  ì‹¶ì–´ìš”!!",
    "ì²˜ìŒ ë¨¹ì–´ë³´ëŠ” ì§€ì¤‘í•´ì‹ ìŒì‹ì¸ë° í•œêµ­ì¸ì˜ ì…ë§›ì— ë§ê²Œ ë³€í˜•í•˜ì‹  ê±° ê°™ì•„ì„œ ì œ ì…ë§›ì—ë„ ë§ì•˜ì–´ìš” ë¹„ì£¼ì–¼ë„ ë„ˆë¬´ í›Œë¥­í•©ë‹ˆë‹¤ ã…ã…",
    "ë§›ìˆê³  íŠ¹ë³„í•œ ë©”ë‰´ê°€ ìˆì–´ìš”~~~â™¥ ë‹¤ìŒì— ë˜ ê°€ê³  ì‹¶ì–´ìš”~~~!!",
    "í‰ì†Œ ë¨¹ì–´ë³¼ ìˆ˜ ì—†ëŠ” ì¢…ë¥˜ì˜ ìŒì‹ì´ë¼ ë°©ë¬¸í–ˆëŠ”ë°... ë¶„ìœ„ê¸°ë„ ì¢‹ê³  ë§›ìˆì—ˆì–´ìš”. ì‹ë¹µ ë¦¬í•„ë„ í•´ì£¼ì…¨ì–´ìš”.",
    "ì‹ ì„ í•œ ê²½í—˜ì´ì—ˆì–´ìš”^^",
    "ê¸¸ê°€ë‹¤ ìš°ì—°íˆ ë³¸ ì‹ë‹¹ì¸ë° ì™¸ê´€ë„ ë„ˆë¬´ ì¢‹ê³  ë¬´ì—‡ë³´ë‹¤ ìŒì‹ë§›ì´ ë„ˆë¬´ ë§›ìˆê³  ì„¼ìŠ¤ìˆì–´ì„œ ì§±ì´ë„¤ìš”! ë‹¤ìŒì— ë˜ ë°©ë¬¸í•˜ê² ìŠµë‹ˆë‹¤",
    "ê·¸ëƒ¥ ìŒì‹ìì²´ê°€ ì¡´ë§›íƒ±, ì´ê±¸ ë¨¹ê¸°ìœ„í•´ íƒœì–´ë‚¬ë‹¤ëŠ”ê²Œ ëŠê»´ì§€ë„¤ìš” êµ³êµ³",

    "ì˜¤ëŠ˜ ì§ì¥ìƒì‚¬ê°€ ì§œì¦ë‚˜ê²Œ í•´ì„œ í™”ê°€ ë‚¬ëŠ”ë° ìŒì‹ìœ¼ë³´ìë§ˆì ê¸°ë¶„ì´ í™• í’€ë ¸ë„¤ìš” ì–‘ë„ ë§ê³  ë§›ë„ í™”ëˆí•˜ê³  ë„ˆë¬´ ì¢‹ì•„ìš”",
    "ê¸¸ê°€ë‹¤ê°€ ëŒì— ë„˜ì–´ì ¸ì„œ ì•„íŒŒì„œ ì¬ìˆ˜ì—†ë‹¤ ìƒê°í•´ì„œ ì§œì¦ë‚¬ëŠ”ë° ì´ê±° ë¨¹ê³  ì²œêµ­ì— ì˜¨ê±°ê°™ì€ ëŠë‚Œì„ ë°›ì•˜ìŠµë‹ˆë‹¤ ì•„ë©˜",

    "ë‚¨ì¹œì´ë‘ ë°ì´íŠ¸í•˜ë¡œ ì™”ëŠ”ë° ì•„ë‹ˆ ì´ê²Œ ì™ ê±¸? ë¶„ìœ„ê¸°ë„ ì¢‹ê³  ì´›ë¶ˆë„ ìˆëŠ”ê²Œ ì•„ëŠ‘í•œê²Œ ë°ì´íŠ¸ì½”ìŠ¤ë¡œ ì™„ì „ ë”±ì´ë„¤ìš”! ë‹¤ìŒì—ë„ ë°©ë¬¸í• ê²Œìš”~",
    "ì—¬ì¹œì´ ëë‚´ì£¼ëŠ” ê°€ê²Œ ì˜ˆì•½ì•ˆí•˜ë©´ ì£½ëŠ”ë‹¤ê³ í•´ì„œ ê²¨ìš°ê²¨ìš° ì°¾ì•˜ìŠµë‹ˆë‹¤. ì™„ì „ ì»¤í”Œë“¤ì˜ ì„±ì§€! ì—¬ìì¹œêµ¬ê°€ ë„ˆë¬´ ë§ˆìŒì— ë“¤ì–´í•˜ë„¤ìš”! ê°ì‚¬í•©ë‹ˆë‹¤",

    "ì˜¤ë«ë™ì•ˆ í‚¤ìš´ ì €í¬ ê°•ì•„ì§€ê°€ í•˜ëŠ˜ì—ê°€ì„œ ë„ˆë¬´ ìš°ìš¸í–ˆëŠ”ë° ì´ ìŒì‹ë¨¹ê³  ë„ˆë¬´ í˜ì´ëë„¤ìš”. ì •ë§ê°ì‚¬í•©ë‹ˆë‹¤",
    "ì–´ë ¸ì„ì  í•´ì¤€ í• ë¨¸ë‹ˆê°€ ìƒê°ë‚˜ëŠ” ë°±ë°˜ì§‘ì´ë„¤ìš”. ê´œíˆ ë¨¹ë‹¤ê°€ ëˆˆë¬¼ì„ í ì¹«í–ˆì–´ìš” ë°‹ë°‹í•˜ì§€ë§Œ ì§‘ë°¥ì˜ ëŠë‚Œì„ ë¨¹ê³ ì‹¶ë‹¤ë©´ ê°•ì¶”ë“œë ¤ìš”",

    "ì˜¤ë«ë§Œì— ë™ì°½íšŒë¥¼ í–ˆëŠ”ë° ì¦ê¸°ê¸° ë„ˆë¬´ ì¢‹ì€ê³³ì´ë„¤ìš” ì‹œëŒì‹œëŒí•˜ê²Œ ì¬ë°Œê²Œ ë†€ì•˜ìŠµë‹ˆë‹¤",
    "ì¹œêµ¬ë“¤ì´ë‘ ì—¬í–‰ì™”ëŠ”ë° ì˜¤ê¸¸ì˜í–ˆë„¤ìš” ë„ˆë¬´ ë§›ìˆê²Œ ë¨¹ê³  ì¬ë°Œê²Œ ì¦ê¸°ë‹¤ ê°‘ë‹ˆë‹¤ ìˆ˜ê³ ë§",

    "ì§ì›ì„œë¹„ìŠ¤ ë­ì„? ê³ ê°ì„ ì¡´ì¤‘í•˜ëŠ” íƒœë„ê°€ ì—†ë„¤ìš”. ë§›ì´ ì—†ìœ¼ë©´ ì„œë¹„ìŠ¤ë¼ë„ ì¢‹ì•„ì•¼í•˜ëŠ”ë° ì–¼ë§ˆ ëª»ê°ˆê°€ê²Œê°™ì•„ìš” ã…ã…",
    "ê³ ê¸°ìŠ¤í”„ì—ì„œ ìƒì„ ë¹„ë¦°ë‚´ê°€ ë‚˜ëŠ” ë ˆì „ë“œê°€ê²Œë°œìƒ ì™¸ê´€ë§Œ ì¢‹ì€ ê°œì‚´êµ¬ë§ˆëƒ¥ ë§›ì´ ì—†ë„¤ìš” ë‹¤ìŒì—ëŠ” ë°©ë¬¸ì•ˆí• ë“¯ìš”."
]

THRESHOLD = 0.5
results_list = []

for text in test_sentences:
    predicted_label, confidence, all_scores = predict_multi_emotion(text, my_models, tokenizer)
    final_label = predicted_label
    if confidence < THRESHOLD:
        final_label = "ë¬´ê°ì •/ëª¨ë¦„"

    print(f"ë¬¸ì¥: {text[:30]}...")
    print(f"ğŸ‘‰ ê²°ê³¼: {final_label} ({confidence*100:.2f}%)")
    print("-" * 50)

    row_data = {'ë¦¬ë·°ë‚´ìš©': text, 'ìµœì¢…ì˜ˆì¸¡': final_label, 'í™•ì‹ ë„': f"{confidence:.2f}", '1ìˆœìœ„ê°ì •': predicted_label}
    row_data.update(all_scores)
    results_list.append(row_data)

df = pd.DataFrame(results_list)
file_name = "./EMOTION_RESULT/emotion_analysis_result.csv"

if not os.path.exists("./EMOTION_RESULT"):
    os.makedirs("./EMOTION_RESULT")

if os.path.exists(file_name):
    df.to_csv(file_name, mode='a', index=False, header=False, encoding='utf-8-sig')
    print(f"\nâœ… ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€ë¨: {file_name}")
else:
    df.to_csv(file_name, mode='w', index=False, header=True, encoding='utf-8-sig')
    print(f"\nâœ… ìƒˆ íŒŒì¼ ìƒì„±ë¨: {file_name}")